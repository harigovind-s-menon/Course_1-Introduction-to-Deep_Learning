{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harigovind-s-menon/Course_1-Introduction-to-Deep_Learning/blob/master/week5/Programming%20Assignment%201%20-%20Generating%20names%20with%20RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oR_cQ3QVNt2-"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w0wq0S9uNyvc",
        "outputId": "294abfd5-f43d-4913-f62e-bcee1fcacae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-08-22 07:58:06--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-22 07:58:06 (90.3 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "colab_type": "code",
        "id": "yT8dmD3GNt3C",
        "outputId": "94edd120-9291-4523-e791-b58b17315eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7kLPIdz3Nt3F"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "colab_type": "code",
        "id": "ao8-rJEcNt3G",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "colab_type": "code",
        "id": "goAOY4_bNt3I",
        "outputId": "39072cae-51b9-44c3-96bd-c83e0fa0a59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "colab_type": "code",
        "id": "gFQiaRl5Nt3M",
        "outputId": "fd322440-0414-4a7b-b9fa-def533220974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zOwFANEENt3Q"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "colab_type": "code",
        "id": "2WGjAlpyNt3R",
        "outputId": "b1b45a52-3bea-491e-dd10-d292ffd2bf30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens = list(set(list(''.join(names[:]))))### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j36vmob-Nt3W"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "colab_type": "code",
        "id": "wKU5qFjSNt3X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5948aee9-189f-4561-c5c7-3e01ca2fdc24"
      },
      "source": [
        "token_to_id = { token : i for i, token in enumerate((tokens))} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "print(token_to_id)\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'w': 0, 'O': 1, 'F': 2, 'U': 3, 'p': 4, 'd': 5, 'u': 6, 't': 7, 'X': 8, 'l': 9, 'b': 10, 'i': 11, 'v': 12, 'M': 13, 'B': 14, ' ': 15, 'Y': 16, 'f': 17, 'Q': 18, 'z': 19, 'o': 20, 'G': 21, 'K': 22, 's': 23, 'Z': 24, 'P': 25, 'L': 26, 'A': 27, 'c': 28, 'T': 29, 'm': 30, 'D': 31, 'W': 32, 'g': 33, 'S': 34, 'E': 35, 'r': 36, 'N': 37, 'j': 38, 'k': 39, 'J': 40, 'R': 41, 'q': 42, 'y': 43, '-': 44, 'h': 45, 'a': 46, 'I': 47, 'H': 48, 'V': 49, 'n': 50, \"'\": 51, 'C': 52, 'x': 53, 'e': 54}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "colab_type": "code",
        "id": "EffSdj9ONt3b",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "colab_type": "code",
        "id": "FTaBHt8HNt3h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "33fb484b-8f38-4972-cbbc-4fbc45032f96"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[15 27 10 46 33 46 54  9  0]\n",
            " [15 21  9 20 36 43  0  0  0]\n",
            " [15 25 36 11 23 23 11 54  0]\n",
            " [15 21 11 20 12 46 50 50 54]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u9OEpFYfNt3r"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/harigovind-s-menon/Course_1-Introduction-to-Deep_Learning/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "colab_type": "code",
        "id": "_5lVAfUiNt3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "4e8a5801-896e-4d72-fb5a-82f04e0d4a26"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0822 07:58:22.099322 140590071138176 deprecation_wrapper.py:119] From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0822 07:58:22.101406 140590071138176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0822 07:58:22.102773 140590071138176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0822 07:58:22.116050 140590071138176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0822 07:58:22.116862 140590071138176 deprecation_wrapper.py:119] From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "colab_type": "code",
        "id": "Hi7HVIL_Nt3-",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OYXwNmZZNt4E"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/harigovind-s-menon/Course_1-Introduction-to-Deep_Learning/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "colab_type": "code",
        "id": "0BmvUy9cNt4F",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb,h_t],1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YcLLrmxTNt4H"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "colab_type": "code",
        "id": "t0lgYuqiNt4I",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lVUg0f13Nt4P"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "colab_type": "code",
        "id": "MJf_nFHhNt4Q",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kW82Scq4Nt4X"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "colab_type": "code",
        "id": "ehVvJknsNt4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3647e738-5319-4110-d572-e176ef1efc6f"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*tf.log(tf.clip_by_value(predictions_matrix,1e-10,1.0)), reduction_indices=[1])) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0822 08:01:46.554444 140590071138176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24wK3UnVNt4e"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "colab_type": "code",
        "id": "VRFBB-TzNt4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1241c323-0ad0-4e51-a084-c9e0c56ab0f0"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngTS4K6WUA2lwV0opB/r/c8gls0XPDMgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fJ9PoKuSNt4k"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "colab_type": "code",
        "id": "fWRWkNu7Nt4l",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "colab_type": "code",
        "id": "YyPIszb7Nt4p",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "colab_type": "code",
        "id": "N7OYTVQ6Nt4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0a8d8733-584a-4dc7-c6eb-9a8b8d1eac27"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Tarriwwwwwwwwww\n",
            " Minfowwwwwwwwww\n",
            " Aldbawwwwwwwwww\n",
            " Jaleliwwwwwwwww\n",
            " Rewwwwwwwnwwwww\n",
            " Ginkawwwwwwwwww\n",
            " Karinwwwwwwwwww\n",
            " ItenMywwwwwwwww\n",
            " Aritawwwwwwwwww\n",
            " Tanteywwwwwwwww\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "colab_type": "code",
        "id": "56kyPRfQNt5B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1a54cde6-84ea-431d-e90f-3e2a25335b02"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpwwwwwwwwww\n",
            " Trumpilwwwwwwww\n",
            " Trumpawwwwwwwww\n",
            " Trumpewwwwwwwww\n",
            " Trumpewwwwwwwww\n",
            " Trumpiewwwwwwww\n",
            " Trumpomwwwwwwww\n",
            " Trumpawwwwwwwww\n",
            " Trumpawwwwwwwww\n",
            " Trumpaanwwwwwww\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aUwOclszNt5G"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "colab_type": "code",
        "id": "RppzOKCxNt5H",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"TcxUlhWbXYHAgAEz\"\n",
        "COURSERA_EMAIL = \"harigovind.sasidharan@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "colab_type": "code",
        "id": "IG3fLGiWNt5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5b98077-35c3-4c69-ca23-0dcd680d8a9e"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "61lnaqMpNt5M"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "9VW3dcSUNt5N"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "colab_type": "code",
        "id": "kgQa8TcSNt5O",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zp5yyAo-Nt5V"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "colab_type": "code",
        "id": "CF8uv-6cNt5X",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "colab_type": "code",
        "id": "IPj53gKANt5a",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}